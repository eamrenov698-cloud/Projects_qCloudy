{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d8650c-3029-4ad2-bf7e-7bfe7bcb6cc9",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a907af33-724f-4be6-894d-f18e48f8402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_cols = [\"Цена\", \"Высота\", \"Диаметр нижних веток\"]\n",
    "cat_cols = [\"Особенности\", \"Тип\", \"Тип конструкции\", \"Количество ярусов\", \"Материал веток\", \"Цвет\", \"Оптоволокно\", \"Крепление веток\", \"Сборка\", \n",
    "           \"Подставка\", \"is_expensive\", \"is_tall\"]\n",
    "target_col = \"Вес\"\n",
    "\n",
    "df = pd.read_excel(\"kaspitrees_filtered.xlsx\")\n",
    "df['is_expensive'] = (df['Цена'] > df['Цена'].quantile(0.75)).astype(int)\n",
    "df['is_tall'] = (df['Высота'] > df['Высота'].quantile(0.75)).astype(int)\n",
    "\n",
    "cat_maps = {}\n",
    "for col in cat_cols:\n",
    "    df[col], cat_maps[col] = pd.factorize(df[col])\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "X_num = df[num_cols].values.astype(np.float32)\n",
    "X_cat = df[cat_cols].values.astype(np.int64)\n",
    "y = df[target_col].values.astype(np.float32)\n",
    "\n",
    "Xn_train, Xn_val, Xc_train, Xc_val, y_train, y_val = train_test_split(\n",
    "    X_num, X_cat, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dec608-06ea-4692-a56b-64a5c33c96a0",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c8ea91c-4e42-4d6a-b7ee-5ad52799d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Encode categoricals as integers\n",
    "cat_maps = {}\n",
    "for col in cat_cols:\n",
    "    df[col], cat_maps[col] = pd.factorize(df[col])\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "X_num = df[num_cols].values.astype(np.float32)\n",
    "X_cat = df[cat_cols].values.astype(np.int64)\n",
    "y = df[target_col].values.astype(np.float32)\n",
    "\n",
    "Xn_train, Xn_val, Xc_train, Xc_val, y_train, y_val = train_test_split(\n",
    "    X_num, X_cat, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb9580-71b4-423a-b7e4-000dc409749d",
   "metadata": {},
   "source": [
    "# 3. PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6129ad6-9722-444a-abfa-61f350c040e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, y):\n",
    "        self.X_num = torch.tensor(X_num)\n",
    "        self.X_cat = torch.tensor(X_cat)\n",
    "        self.y = torch.tensor(y).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_ds = ProductDataset(Xn_train, Xc_train, y_train)\n",
    "val_ds   = ProductDataset(Xn_val, Xc_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99618037-21b1-4349-9b98-31d60157602d",
   "metadata": {},
   "source": [
    "# 4. Mixture Density Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b09ddd3f-8740-4694-8eb3-50305276f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    def __init__(self, num_features, cat_cardinalities, emb_dim=8, K=3):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "\n",
    "        # Embeddings for categorical features\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(card, emb_dim) for card in cat_cardinalities\n",
    "        ])\n",
    "\n",
    "        total_input_dim = num_features + emb_dim * len(cat_cardinalities)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(total_input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # MDN heads\n",
    "        self.pi = nn.Linear(128, K)      # mixing coefficients\n",
    "        self.mu = nn.Linear(128, K)      # means\n",
    "        self.sigma = nn.Linear(128, K)   # stds\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        embs = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat([x_num] + embs, dim=1)\n",
    "\n",
    "        h = self.net(x)\n",
    "\n",
    "        pi = torch.softmax(self.pi(h), dim=1)\n",
    "        mu = self.mu(h)\n",
    "        sigma = torch.exp(self.sigma(h)) + 1e-6\n",
    "\n",
    "        return pi, mu, sigma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2060b6ee-e53c-4ac5-9363-46a36bc0ed85",
   "metadata": {},
   "source": [
    "# 5. MDN loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e38a08a6-d99c-41b9-be1f-e54788ff5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_loss(pi, mu, sigma, y):\n",
    "    y = y.expand_as(mu)\n",
    "    normal = torch.distributions.Normal(mu, sigma)\n",
    "    log_prob = normal.log_prob(y)\n",
    "    weighted = log_prob + torch.log(pi + 1e-8)\n",
    "    return -torch.logsumexp(weighted, dim=1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20eee49-95af-47f2-b86f-e12a3ba0fe26",
   "metadata": {},
   "source": [
    "# 6. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f8866c8-d0ea-45ed-af51-e856f9e87e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train 14.4776 | Val 4.1769\n",
      "Epoch 002 | Train 4.4301 | Val 4.5455\n",
      "Epoch 003 | Train 4.2497 | Val 3.8762\n",
      "Epoch 004 | Train 3.6867 | Val 3.4783\n",
      "Epoch 005 | Train 3.4887 | Val 3.3831\n",
      "Epoch 006 | Train 3.4141 | Val 3.3303\n",
      "Epoch 007 | Train 3.3608 | Val 3.2347\n",
      "Epoch 008 | Train 3.2501 | Val 3.1120\n",
      "Epoch 009 | Train 3.1276 | Val 2.8967\n",
      "Epoch 010 | Train 2.9272 | Val 2.7915\n",
      "Epoch 011 | Train 2.8606 | Val 2.7701\n",
      "Epoch 012 | Train 2.8234 | Val 2.7466\n",
      "Epoch 013 | Train 2.7986 | Val 2.7269\n",
      "Epoch 014 | Train 2.7653 | Val 2.7239\n",
      "Epoch 015 | Train 2.7441 | Val 2.7019\n",
      "Epoch 016 | Train 2.7215 | Val 2.6944\n",
      "Epoch 017 | Train 2.7055 | Val 2.7050\n",
      "Epoch 018 | Train 2.7123 | Val 2.6905\n",
      "Epoch 019 | Train 2.7040 | Val 2.6748\n",
      "Epoch 020 | Train 2.6943 | Val 2.6852\n",
      "Epoch 021 | Train 2.6709 | Val 2.6685\n",
      "Epoch 022 | Train 2.6672 | Val 2.6714\n",
      "Epoch 023 | Train 2.6672 | Val 2.6679\n",
      "Epoch 024 | Train 2.6417 | Val 2.6698\n",
      "Epoch 025 | Train 2.6266 | Val 2.6755\n",
      "Epoch 026 | Train 2.6160 | Val 2.6647\n",
      "Epoch 027 | Train 2.6057 | Val 2.6575\n",
      "Epoch 028 | Train 2.5816 | Val 2.6606\n",
      "Epoch 029 | Train 2.5838 | Val 2.6631\n",
      "Epoch 030 | Train 2.5869 | Val 2.6592\n",
      "Epoch 031 | Train 2.5688 | Val 2.6527\n",
      "Epoch 032 | Train 2.5585 | Val 2.6570\n",
      "Epoch 033 | Train 2.5808 | Val 2.6581\n",
      "Epoch 034 | Train 2.5526 | Val 2.6644\n",
      "Epoch 035 | Train 2.5549 | Val 2.6408\n",
      "Epoch 036 | Train 2.5365 | Val 2.6825\n",
      "Epoch 037 | Train 2.5240 | Val 2.6391\n",
      "Epoch 038 | Train 2.5053 | Val 2.6193\n",
      "Epoch 039 | Train 2.4788 | Val 2.6496\n",
      "Epoch 040 | Train 2.4930 | Val 2.6471\n",
      "Epoch 041 | Train 2.5014 | Val 2.6377\n",
      "Epoch 042 | Train 2.4370 | Val 2.6530\n",
      "Epoch 043 | Train 2.4383 | Val 2.6395\n",
      "Epoch 044 | Train 2.4235 | Val 2.6470\n",
      "Epoch 045 | Train 2.4189 | Val 2.6492\n",
      "Epoch 046 | Train 2.4342 | Val 2.6413\n",
      "Epoch 047 | Train 2.4261 | Val 2.6670\n",
      "Epoch 048 | Train 2.3743 | Val 2.6216\n",
      "Epoch 049 | Train 2.3458 | Val 2.6790\n",
      "Epoch 050 | Train 2.3587 | Val 2.7195\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cat_cardinalities = [df[col].nunique() for col in cat_cols]\n",
    "\n",
    "model = MDN(\n",
    "    num_features=len(num_cols),\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    K=3\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for x_num, x_cat, y in train_loader:\n",
    "        x_num, x_cat, y = x_num.to(device), x_cat.to(device), y.to(device)\n",
    "\n",
    "        pi, mu, sigma = model(x_num, x_cat)\n",
    "        loss = mdn_loss(pi, mu, sigma, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_num, x_cat, y in val_loader:\n",
    "            x_num, x_cat, y = x_num.to(device), x_cat.to(device), y.to(device)\n",
    "            pi, mu, sigma = model(x_num, x_cat)\n",
    "            val_loss += mdn_loss(pi, mu, sigma, y).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:03d} | Train {train_loss/len(train_loader):.4f} | Val {val_loss/len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63d87d-d881-4f2a-b244-c9fdbc37a7da",
   "metadata": {},
   "source": [
    "# 7. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df917f12-06c3-46db-9083-ae84fd099287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_expected(model, x_num, x_cat):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pi, mu, _ = model(x_num, x_cat)\n",
    "        return torch.sum(pi * mu, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae60f45-98e8-4a55-a191-e2f06f418e97",
   "metadata": {},
   "source": [
    "# Sampling from trimodal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1163b09b-44b8-400e-adc4-e371a97f9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mdn(pi, mu, sigma):\n",
    "    cat = torch.distributions.Categorical(pi)\n",
    "    idx = cat.sample()\n",
    "    chosen_mu = mu.gather(1, idx.unsqueeze(1)).squeeze()\n",
    "    chosen_sigma = sigma.gather(1, idx.unsqueeze(1)).squeeze()\n",
    "    return torch.normal(chosen_mu, chosen_sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fd5a1-d96f-4267-8afe-f93ddb7f6838",
   "metadata": {},
   "source": [
    "# 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa0c5f7e-8c80-4839-aeea-ff97ea1fb504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MDN Evaluation =====\n",
      "NLL (distribution): 2.7195\n",
      "MAE (mean):         3.1024\n",
      "RMSE (mean):        4.5337\n",
      "MAE (mode):         3.0167\n",
      "RMSE (mode):        4.5407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_targets = []\n",
    "all_mean_preds = []\n",
    "all_mode_preds = []\n",
    "all_nll = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, y in val_loader:\n",
    "        x_num = x_num.to(device)\n",
    "        x_cat = x_cat.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pi, mu, sigma = model(x_num, x_cat)\n",
    "\n",
    "        # --- NLL (primary MDN metric)\n",
    "        loss = mdn_loss(pi, mu, sigma, y)\n",
    "        all_nll.append(loss.item())\n",
    "\n",
    "        # --- Expected value prediction\n",
    "        mean_pred = torch.sum(pi * mu, dim=1)\n",
    "\n",
    "        # --- Most probable mode prediction\n",
    "        mode_idx = torch.argmax(pi, dim=1)\n",
    "        mode_pred = mu.gather(1, mode_idx.unsqueeze(1)).squeeze()\n",
    "\n",
    "        all_mean_preds.append(mean_pred.cpu().numpy())\n",
    "        all_mode_preds.append(mode_pred.cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy().squeeze())\n",
    "\n",
    "# concatenate\n",
    "y_true = np.concatenate(all_targets)\n",
    "y_mean = np.concatenate(all_mean_preds)\n",
    "y_mode = np.concatenate(all_mode_preds)\n",
    "\n",
    "# scores\n",
    "nll  = np.mean(all_nll)\n",
    "mae_mean  = mean_absolute_error(y_true, y_mean)\n",
    "rmse_mean = root_mean_squared_error(y_true, y_mean)\n",
    "\n",
    "mae_mode  = mean_absolute_error(y_true, y_mode)\n",
    "rmse_mode = root_mean_squared_error(y_true, y_mode)\n",
    "\n",
    "print(\"===== MDN Evaluation =====\")\n",
    "print(f\"NLL (distribution): {nll:.4f}\")\n",
    "print(f\"MAE (mean):         {mae_mean:.4f}\")\n",
    "print(f\"RMSE (mean):        {rmse_mean:.4f}\")\n",
    "print(f\"MAE (mode):         {mae_mode:.4f}\")\n",
    "print(f\"RMSE (mode):        {rmse_mode:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "739c4365-c0a5-4174-9787-33054ea5b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage ±1σ: 75.8% (ideal ≈ 68%)\n",
      "Coverage ±2σ: 92.2% (ideal ≈ 95%)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    cover_1, cover_2 = [], []\n",
    "\n",
    "    for x_num, x_cat, y in val_loader:\n",
    "        x_num, x_cat, y = x_num.to(device), x_cat.to(device), y.to(device)\n",
    "\n",
    "        pi, mu, sigma = model(x_num, x_cat)\n",
    "\n",
    "        mean = torch.sum(pi * mu, dim=1)\n",
    "        var = torch.sum(pi * (sigma**2 + mu**2), dim=1) - mean**2\n",
    "        std = torch.sqrt(var)\n",
    "\n",
    "        cover_1.append(((y.squeeze() - mean).abs() <= std).float().mean().item())\n",
    "        cover_2.append(((y.squeeze() - mean).abs() <= 2*std).float().mean().item())\n",
    "\n",
    "print(f\"Coverage ±1σ: {np.mean(cover_1)*100:.1f}% (ideal ≈ 68%)\")\n",
    "print(f\"Coverage ±2σ: {np.mean(cover_2)*100:.1f}% (ideal ≈ 95%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d188b-a44a-4ef5-96bd-ccf7a99bae9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
